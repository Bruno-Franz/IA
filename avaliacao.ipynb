{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef74faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Funções para avaliar e agregar resultados de modelos.\"\"\"\n",
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5222fed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b0b982",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5f9616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443c57ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliar_dataset(df: pd.DataFrame, target: str) -> List[Dict[str, float]]:\n",
    "    \"\"\"Train simple models on *df* and return metrics.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing features and the target column.\n",
    "    target : str\n",
    "        Name of the target column in ``df``.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[Dict[str, float]]\n",
    "        List with one metrics dictionary per model. Each dictionary contains the\n",
    "        keys ``method``, ``accuracy``, ``precision``, ``recall`` and ``f1``.\n",
    "    \"\"\"\n",
    "    # separa dados e treina modelos simples\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"GaussianNB\": GaussianNB(),\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, preds)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            y_test, preds, average=\"weighted\", zero_division=0\n",
    "        )\n",
    "        results.append(\n",
    "            {\n",
    "                \"method\": name,\n",
    "                \"accuracy\": acc,\n",
    "                \"precision\": precision,\n",
    "                \"recall\": recall,\n",
    "                \"f1\": f1,\n",
    "            }\n",
    "        )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5ca6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_resultados(csv_path: str) -> Mapping[str, pd.DataFrame]:\n",
    "    \"\"\"Group ``results.csv`` by dataset and method and average metrics.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_path : str\n",
    "        Path to the CSV generated by the training scripts.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Mapping[str, pandas.DataFrame]\n",
    "        A dictionary mapping each dataset name to a table with the aggregated\n",
    "        metrics for every method tested.\n",
    "    \"\"\"\n",
    "    # agrupa métricas por dataset e método\n",
    "    df = pd.read_csv(csv_path)\n",
    "    metrics = [\"accuracy\", \"precision\", \"recall\", \"f1\", \"duration\"]\n",
    "    grouped = df.groupby([\"dataset\", \"method\"])[metrics].mean().reset_index()\n",
    "\n",
    "    result: Dict[str, pd.DataFrame] = {}\n",
    "    for dataset, table in grouped.groupby(\"dataset\"):\n",
    "        result[dataset] = table.drop(columns=\"dataset\").reset_index(drop=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce51f9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_tabelas(csv_path: str, out_dir: str = \".\", prefix: str = \"table\") -> None:\n",
    "    \"\"\"Create per-dataset tables in CSV and Markdown format.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_path : str\n",
    "        Source results CSV.\n",
    "    out_dir : str, optional\n",
    "        Directory where the tables will be written.\n",
    "    prefix : str, optional\n",
    "        Prefix used for the output filenames.\n",
    "    \"\"\"\n",
    "    # gera arquivos com tabelas sumarizadas\n",
    "    tables = agregar_resultados(csv_path)\n",
    "    out = Path(out_dir)\n",
    "    out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for dataset, table in tables.items():\n",
    "        slug = dataset.lower().replace(\" \", \"_\")\n",
    "        table.to_csv(out / f\"{prefix}_{slug}.csv\", index=False)\n",
    "        try:\n",
    "            markdown = table.to_markdown(index=False)\n",
    "        except ImportError:\n",
    "            markdown = table.to_csv(index=False)\n",
    "        with open(out / f\"{prefix}_{slug}.md\", \"w\", encoding=\"utf-8\") as fh:\n",
    "            fh.write(markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2172be",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"Aggregate training results\")\n",
    "    parser.add_argument(\"csv\", nargs=\"?\", default=\"results.csv\")\n",
    "    parser.add_argument(\"--out-dir\", default=\".\")\n",
    "    parser.add_argument(\"--prefix\", default=\"table\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    gerar_tabelas(args.csv, out_dir=args.out_dir, prefix=args.prefix)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
