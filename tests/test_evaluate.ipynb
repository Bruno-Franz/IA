{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bacb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Testes para a função de avaliação de modelos.\"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28dea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avaliacao import avaliar_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9c3161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_avaliar_dataset_retorna_tres_dicts_com_chaves():\n",
    "    X, y = make_classification(n_samples=30, n_features=4, n_informative=2, random_state=0)\n",
    "    df = pd.DataFrame(X, columns=[f\"f{i}\" for i in range(X.shape[1])])\n",
    "    df[\"label\"] = y\n",
    "\n",
    "    results = avaliar_dataset(df, target=\"label\")\n",
    "\n",
    "    assert isinstance(results, list)\n",
    "    assert len(results) == 3\n",
    "    expected_keys = {\"method\", \"accuracy\", \"precision\", \"recall\", \"f1\"}\n",
    "    for res in results:\n",
    "        assert expected_keys == set(res.keys())"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
