{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da4a8f50",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"TrabalhoIA2.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1ICKWHmssmG1nmBGYllxTiMEY5lHPRxI9\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7693a49",
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a891ce3",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank.zip\"\n",
        "!wget -q $url       # baixa o ZIP\n",
        "!unzip -q bank.zip  # extrai bank-full.csv e outros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f76c6ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"bank-full.csv\", sep=\";\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40847927",
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "337e057d",
      "metadata": {},
      "outputs": [],
      "source": [
        "(ds_train, ds_val, ds_test), info = tfds.load(\n",
        "    \"tf_flowers\",\n",
        "    split=[\"train[:80%]\", \"train[80%:90%]\", \"train[90%:]\"],\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "print(\"Classes:\", info.features[\"label\"].names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7f6cb84",
      "metadata": {},
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed3bf6d1",
      "metadata": {},
      "source": [
        "Etapa 1: Upload manual do arquivo ZIP no Colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbee9ba0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Etapa 2: Extrair o ZIP externo\n",
        "outer_zip_path = '/content/bank+marketing.zip'\n",
        "outer_extract_path = '/content/bank_outer'\n",
        "with zipfile.ZipFile(outer_zip_path, 'r') as outer_zip:\n",
        "    outer_zip.extractall(outer_extract_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "819ac881",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Etapa 3: Extrair o ZIP interno (bank.zip)\n",
        "inner_zip_path = os.path.join(outer_extract_path, 'bank.zip')\n",
        "inner_extract_path = '/content/bank_data'\n",
        "with zipfile.ZipFile(inner_zip_path, 'r') as inner_zip:\n",
        "    inner_zip.extractall(inner_extract_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "349fc6a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Etapa 4: Listar e carregar o CSV principal\n",
        "print(\"Arquivos disponíveis:\", os.listdir(inner_extract_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a334fdfb",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(os.path.join(inner_extract_path, 'bank.csv'), sep=';')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e28e5e88",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "940909ee",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Converter variáveis binárias para 0/1\n",
        "df_bin = df.copy()\n",
        "binary_map = {'yes': 1, 'no': 0}\n",
        "for col in ['default', 'housing', 'loan', 'y']:\n",
        "    df_bin[col] = df_bin[col].map(binary_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a26308a2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. One-hot encoding nas variáveis categóricas\n",
        "categorical_cols = ['job', 'marital', 'education', 'contact', 'month', 'poutcome']\n",
        "df_encoded = pd.get_dummies(df_bin, columns=categorical_cols, drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cedb147a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Separar X (features) e y (rótulo)\n",
        "X = df_encoded.drop('y', axis=1)\n",
        "y = df_encoded['y']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "360935c1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Padronizar colunas numéricas\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da457c18",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Dividir em treino e teste (80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5165f4fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "042ed186",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ed04169",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lista de configurações de hiperparâmetros\n",
        "params_list = [\n",
        "    {\"criterion\": \"gini\", \"max_depth\": None},\n",
        "    {\"criterion\": \"entropy\", \"max_depth\": 5},\n",
        "    {\"criterion\": \"gini\", \"max_depth\": 10, \"min_samples_split\": 10}\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16fff3fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lista para guardar resultados\n",
        "results_dt = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edf53b3f",
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, params in enumerate(params_list, 1):\n",
        "    clf = DecisionTreeClassifier(random_state=42, **params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    results_dt.append({\n",
        "        \"Configuração\": f\"Configuração {i}\",\n",
        "        \"Hiperparâmetros\": params,\n",
        "        \"Acurácia\": acc,\n",
        "        \"Precisão (classe 1)\": report['1']['precision'],\n",
        "        \"Recall (classe 1)\": report['1']['recall'],\n",
        "        \"F1-score (classe 1)\": report['1']['f1-score']\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e0820ad",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mostrar resultados\n",
        "import pandas as pd\n",
        "pd.DataFrame(results_dt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "125c1b9e",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"# Task\n",
        "Carrega o conjunto de resenhas de livros em português para classificar sentimentos.\n",
        "\n",
        "Here is all the data you need:\n",
        "\"archive/books_reviews.csv\"\n",
        "\n",
        "## Data loading\n",
        "\n",
        "### Subtask:\n",
        "Load the dataset \"archive/books_reviews.csv\" into a pandas DataFrame.\n",
        "\n",
        "**Reasoning**:\n",
        "Carregar a base de resenhas já combinada em um único CSV local e exibir informações básicas.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bea1beb",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87049fb4",
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    df = pd.read_csv('archive/books_reviews.csv')\n",
        "except UnicodeDecodeError:\n",
        "    try:\n",
        "        df = pd.read_csv('archive/books_reviews.csv', encoding='latin-1')\n",
        "    except UnicodeDecodeError:\n",
        "        try:\n",
        "            df = pd.read_csv('archive/books_reviews.csv', encoding='utf-8')\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading the file: {e}\")\n",
        "            df = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9080a9aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "if df is not None:\n",
        "    display(df.head())\n",
        "    print(df.shape)\n",
        "    df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c7790ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"## Data exploration\n",
        "\n",
        "### Subtask:\n",
        "Explorar rapidamente a base de resenhas, verificando quantidade de exemplos por classe e tamanho médio dos textos.\n",
        "\n",
        "**Reasoning**:\n",
        "Como o conjunto possui apenas duas colunas (texto e rótulo), a análise pode ser simplificada para foco na distribuição das classes e nas estatísticas básicas das resenhas.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56df7f7a",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Shape of the DataFrame:\", df.shape)\n",
        "print(df['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2d62c0a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# calcular o comprimento médio das resenhas\n",
        "df['text_length'] = df['review_text'].astype(str).apply(len)\n",
        "print(\"Tamanho médio do texto:\", df['text_length'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82bb0ce1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ca63388",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x='label', data=df)\n",
        "plt.title('Distribuição das classes')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c11968e3",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "sns.histplot(df['text_length'], kde=True)\n",
        "plt.title('Distribuição do tamanho das resenhas')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "734df89e",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"# Task\n",
        "eu tenho uma base aqui que eu preciso subir para cá e que você consiga fazer a leitura desses dados para fazer um pré-processamento dos dados para depois aplicar os métodos como de árvore de decisão e quem saber uma rede neural, como eu subo?\n",
        "\n",
        "Here is all the data you need:\n",
        "\"B2W-Reviews01.csv\"\n",
        "\n",
        "## Data loading\n",
        "\n",
        "### Subtask:\n",
        "Load the dataset \"B2W-Reviews01.csv\" into a pandas DataFrame.\n",
        "\n",
        "**Reasoning**:\n",
        "Load the dataset \"B2W-Reviews01.csv\" into a pandas DataFrame and display basic information about it.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3fa0617",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a11e5f8",
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    df = pd.read_csv('B2W-Reviews01.csv')\n",
        "except UnicodeDecodeError:\n",
        "    try:\n",
        "        df = pd.read_csv('B2W-Reviews01.csv', encoding='latin-1')\n",
        "    except UnicodeDecodeError:\n",
        "        try:\n",
        "            df = pd.read_csv('B2W-Reviews01.csv', encoding='utf-8')\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading the file: {e}\")\n",
        "            df = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "297c0d34",
      "metadata": {},
      "outputs": [],
      "source": [
        "if df is not None:\n",
        "    display(df.head())\n",
        "    print(df.shape)\n",
        "    df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36d03be9",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"## Data exploration\n",
        "\n",
        "### Subtask:\n",
        "Explore the dataset to understand its structure, identify data types of each column, check for missing values, and examine the distribution of key variables. Determine the shape of the data and look for potential issues like inconsistencies or irrelevant columns.  Pay special attention to the 'review_comment_title' and 'review_comment_message' columns, as these might contain valuable textual information.\n",
        "\n",
        "**Reasoning**:\n",
        "Explore the dataset, identify data types, check for missing values, examine the distribution of key variables, and look for potential issues.  This involves using .shape, .info(), .describe(), examining unique values for categorical columns, calculating text lengths, and checking for duplicates.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fb1f476",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check the shape of the DataFrame\n",
        "print(\"Shape of the DataFrame:\", df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeedce2b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get a summary of the DataFrame\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df4c114c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Descriptive statistics for numerical columns\n",
        "print(\"\\nDescriptive Statistics:\")\n",
        "display(df.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb5897b1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Examine unique values for categorical columns\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "for col in categorical_cols:\n",
        "    print(f\"\\nUnique values and frequencies for {col}:\")\n",
        "    print(df[col].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "526151e1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate the average length of text in 'review_comment_title' and 'review_comment_message'\n",
        "# Note: These columns are 'review_title' and 'review_text' in the provided data.\n",
        "if 'review_title' in df.columns:\n",
        "    df['review_title_length'] = df['review_title'].astype(str).apply(len)\n",
        "    print(f\"\\nAverage length of review_title: {df['review_title_length'].mean()}\")\n",
        "if 'review_text' in df.columns:\n",
        "    df['review_text_length'] = df['review_text'].astype(str).apply(len)\n",
        "    print(f\"\\nAverage length of review_text: {df['review_text_length'].mean()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "457a20fb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for duplicated rows\n",
        "duplicated_rows = df.duplicated().sum()\n",
        "print(f\"\\nNumber of duplicated rows: {duplicated_rows}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2303776",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"**Reasoning**:\n",
        "Visualize the distribution of key variables using histograms, box plots, and count plots. Pay special attention to the `overall_rating` column. Check for potential outliers or unusual patterns in numerical and categorical features. Also, visualize the correlation matrix using a heatmap.\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8286861c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df710855",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- carregar ---\n",
        "df = pd.read_csv(\"archive/books_reviews.csv\")           # ajuste o caminho se necessário"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53c06e6c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- checagem rápida ---\n",
        "print(df.shape)\n",
        "print(df['label'].value_counts())\n",
        "df['text_length'] = df['review_text'].str.len()\n",
        "print(\"Tamanho médio do texto:\", df['text_length'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e94bb61b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- gráfico 1: distribuição das classes (0 = negativo, 1 = positivo) ---\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x='label', data=df)\n",
        "plt.title('Distribuição das classes')\n",
        "plt.xlabel('label'); plt.ylabel('count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "715f7d88",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- gráfico 2: distribuição do comprimento das resenhas ---\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.histplot(df['text_length'], bins=40, kde=True)\n",
        "plt.title('Distribuição do tamanho das resenhas')\n",
        "plt.xlabel('nº de caracteres')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14c9ae56",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"**Reasoning**:\n",
        "The previous code block failed due to a `ValueError` when trying to compute the correlation matrix because of a string column ('submission_date').  I need to handle this error by excluding non-numeric columns from the correlation calculation.  I'll also improve the plot sizes and add labels and titles to the plots.\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29c8e6c5",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "273543c1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ----- carregar e garantir text_length -----\n",
        "df = pd.read_csv(\"archive/books_reviews.csv\")\n",
        "if \"text_length\" not in df.columns:\n",
        "    df[\"text_length\"] = df[\"review_text\"].str.len()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef3b69f3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ----- distribuição do rótulo (única categórica real) -----\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x=\"label\", data=df)\n",
        "plt.title(\"Distribuição das classes (0 = neg, 1 = pos)\")\n",
        "plt.xlabel(\"label\"); plt.ylabel(\"count\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f46649e5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ----- histograma + boxplot do comprimento do texto -----\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.histplot(df[\"text_length\"], bins=40, kde=True)\n",
        "plt.title(\"Histograma do tamanho das resenhas\"); plt.xlabel(\"nº de caracteres\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "263e594c",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "sns.boxplot(x=df[\"text_length\"])\n",
        "plt.title(\"Box-plot do tamanho das resenhas\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cc6b122",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ----- (opcional) matriz de correlação se houver >1 numérico -----\n",
        "num_cols = df.select_dtypes(include=\"number\").columns\n",
        "if len(num_cols) > 1:\n",
        "    corr = df[num_cols].corr()\n",
        "    plt.figure(figsize=(6,4))\n",
        "    sns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "    plt.title(\"Correlação entre variáveis numéricas\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Só há uma coluna numérica; heatmap de correlação não é necessário.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2b9504c",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"# **Aqui começa a implementação da rede neural**\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bc6c98d",
      "metadata": {},
      "source": [
        "Implementação da rede neural para dados tabulares (Banco)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "825ffb4d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fc89e7f",
      "metadata": {},
      "source": [
        "Carregar os dados pré-processados se ainda não estiverem na memória\n",
        "Certifique-se de que X_train, X_test, y_train, y_test estão disponíveis do pré-processamento anterior"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ddec000",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Arquitetura 1: MLP Básico com Scikit-learn\n",
        "print(\"--- Treinando MLP Básico com Scikit-learn ---\")\n",
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61e6268d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parâmetros: hidden_layer_sizes (número de neurônios por camada), max_iter (épocas)\n",
        "mlp_sk = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)\n",
        "mlp_sk.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd5f77e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_sk = mlp_sk.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37e9d1db",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Relatório de Classificação (MLP Scikit-learn):\")\n",
        "print(classification_report(y_test, y_pred_sk, zero_division=0))\n",
        "print(\"Acurácia (MLP Scikit-learn):\", accuracy_score(y_test, y_pred_sk))\n",
        "print(f\"Tempo de treinamento: {time.time() - start_time:.2f} segundos\")\n",
        "print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1dfc030",
      "metadata": {},
      "source": [
        "Implementação da rede neural para dados de imagem (tf_flowers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7de02ec7",
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd7ab1e5",
      "metadata": {},
      "source": [
        "Certifique-se de que ds_train, ds_val, ds_test estão disponíveis do carregamento anterior"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a13f00d4",
      "metadata": {
        "lines_to_next_cell": 1
      },
      "outputs": [],
      "source": [
        "# Configurações para o pipeline de dados\n",
        "IMG_HEIGHT = 180\n",
        "IMG_WIDTH = 180\n",
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e21146d",
      "metadata": {
        "lines_to_next_cell": 1
      },
      "outputs": [],
      "source": [
        "# Função para redimensionar e normalizar as imagens\n",
        "def preprocess_image(image, label):\n",
        "  image = tf.image.resize(image, (IMG_HEIGHT, IMG_WIDTH))\n",
        "  image = image / 255.0  # Normalização\n",
        "  return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c508c58e",
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_train_processed = ds_train.map(preprocess_image).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "ds_val_processed = ds_val.map(preprocess_image).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "ds_test_processed = ds_test.map(preprocess_image).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a064c38b",
      "metadata": {},
      "source": [
        "Visualizar algumas imagens (opcional)\n",
        "for images, labels in ds_train_processed.take(1):\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy())\n",
        "    plt.title(info.features['label'].names[labels[i].numpy()])\n",
        "    plt.axis(\"off\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01f41ab5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Número de classes\n",
        "num_classes = info.features['label'].num_classes\n",
        "print(f\"Número de classes para imagens: {num_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "861f7db2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Arquitetura 2: CNN Simples\n",
        "print(\"--- Treinando CNN Simples para Imagens ---\")\n",
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "664745d6",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_cnn_simple = keras.Sequential([\n",
        "    layers.Conv2D(32, 3, activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8e20d54",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_cnn_simple.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b968440f",
      "metadata": {},
      "outputs": [],
      "source": [
        "history_cnn_simple = model_cnn_simple.fit(\n",
        "    ds_train_processed,\n",
        "    validation_data=ds_val_processed,\n",
        "    epochs=10 # Pode ajustar o número de épocas\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fde19715",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Avaliando CNN Simples:\")\n",
        "loss_cnn_simple, accuracy_cnn_simple = model_cnn_simple.evaluate(ds_test_processed)\n",
        "print(f\"Loss no Teste: {loss_cnn_simple:.4f}\")\n",
        "print(f\"Acurácia no Teste: {accuracy_cnn_simple:.4f}\")\n",
        "print(f\"Tempo de treinamento: {time.time() - start_time:.2f} segundos\")\n",
        "print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e20d3b13",
      "metadata": {},
      "source": [
        "Implementação da rede neural para dados de texto (archive/books_reviews.csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "071488ca",
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a14d7a93",
      "metadata": {},
      "source": [
        "Certifique-se de que o DataFrame df do archive/books_reviews.csv está disponível"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1566671",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remover linhas com valores NaN na coluna 'review_text' ou 'label'\n",
        "df.dropna(subset=['review_text', 'label'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f60204bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separar textos e rótulos\n",
        "texts = df['review_text'].tolist()\n",
        "labels = df['label'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "809f5402",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tokenização\n",
        "vocab_size = 10000 # Tamanho do vocabulário\n",
        "oov_tok = \"<OOV>\"  # Token para palavras fora do vocabulário\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18f7b1d1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Padding\n",
        "max_length = max([len(x) for x in sequences]) # Comprimento máximo das sequências\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2297525f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dividir em treino e teste\n",
        "X_train_text, X_test_text, y_train_text, y_test_text = train_test_split(\n",
        "    padded_sequences, labels, test_size=0.2, random_state=42, stratify=labels # estratifica para manter a proporção das classes\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ad98130",
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train_text = np.array(y_train_text)\n",
        "y_test_text = np.array(y_test_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba857a3e",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Tamanho do vocabulário: {vocab_size}\")\n",
        "print(f\"Comprimento máximo das sequências: {max_length}\")\n",
        "print(f\"Shape dos dados de treino (texto): {X_train_text.shape}\")\n",
        "print(f\"Shape dos dados de teste (texto): {X_test_text.shape}\")\n",
        "print(f\"Shape dos rótulos de treino (texto): {y_train_text.shape}\")\n",
        "print(f\"Shape dos rótulos de teste (texto): {y_test_text.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d248d146",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Arquitetura 3: CNN Simples para Texto\n",
        "print(\"--- Treinando CNN Simples para Texto ---\")\n",
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9362bc41",
      "metadata": {},
      "outputs": [],
      "source": [
        "embedding_dim = 16 # Dimensão do embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbea5733",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_cnn_text = keras.Sequential([\n",
        "    layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    layers.Conv1D(128, 5, activation='relu'),\n",
        "    layers.GlobalMaxPooling1D(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid') # Sigmoid para classificação binária\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e2915a0",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_cnn_text.compile(optimizer='adam',\n",
        "                       loss='binary_crossentropy',\n",
        "                       metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf04a077",
      "metadata": {},
      "outputs": [],
      "source": [
        "history_cnn_text = model_cnn_text.fit(\n",
        "    X_train_text, y_train_text,\n",
        "    epochs=10, # Pode ajustar o número de épocas\n",
        "    validation_split=0.2 # Usar parte do treino para validação\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6d3014c",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Avaliando CNN Simples para Texto:\")\n",
        "loss_cnn_text, accuracy_cnn_text = model_cnn_text.evaluate(X_test_text, y_test_text)\n",
        "print(f\"Loss no Teste: {loss_cnn_text:.4f}\")\n",
        "print(f\"Acurácia no Teste: {accuracy_cnn_text:.4f}\")\n",
        "print(f\"Tempo de treinamento: {time.time() - start_time:.2f} segundos\")\n",
        "print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8be756c4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Arquitetura 4: MLP Mais Complexo com Keras (Dados Tabulares)\n",
        "print(\"--- Treinando MLP Mais Complexo com Keras ---\")\n",
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30d4db12",
      "metadata": {},
      "source": [
        "Converter dados do scikit-learn para o formato do Keras se necessário\n",
        "X_train_keras, X_test_keras, y_train_keras, y_test_keras = X_train, X_test, y_train, y_test # Se já estiverem no formato numpy/tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0084e513",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_mlp_keras = keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.Dropout(0.3), # Dropout para regularização\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid') # Saída binária para o problema do banco\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e305090",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_mlp_keras.compile(optimizer='adam',\n",
        "                        loss='binary_crossentropy',\n",
        "                        metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54b39ccb",
      "metadata": {},
      "source": [
        "O problema do banco é binário, então usamos binary_crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62eeb618",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Usar um callback para parar o treino se a validação não melhorar\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d130204",
      "metadata": {},
      "outputs": [],
      "source": [
        "history_mlp_keras = model_mlp_keras.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=50, # Pode ajustar o número de épocas\n",
        "    validation_split=0.2, # Usar parte do treino para validação\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b76a946",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Avaliando MLP Mais Complexo com Keras:\")\n",
        "loss_mlp_keras, accuracy_mlp_keras = model_mlp_keras.evaluate(X_test, y_test)\n",
        "print(f\"Loss no Teste: {loss_mlp_keras:.4f}\")\n",
        "print(f\"Acurácia no Teste: {accuracy_mlp_keras:.4f}\")\n",
        "print(f\"Tempo de treinamento: {time.time() - start_time:.2f} segundos\")\n",
        "print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c75ce7c2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Arquitetura 5: CNN Mais Profunda para Imagens\n",
        "print(\"--- Treinando CNN Mais Profunda para Imagens ---\")\n",
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd0a0f1f",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_cnn_deep = keras.Sequential([\n",
        "    layers.Conv2D(32, 3, activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(128, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6bd8627",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_cnn_deep.compile(optimizer='adam',\n",
        "                       loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                       metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ebf8a77",
      "metadata": {},
      "outputs": [],
      "source": [
        "early_stopping_cnn = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfc68380",
      "metadata": {},
      "outputs": [],
      "source": [
        "history_cnn_deep = model_cnn_deep.fit(\n",
        "    ds_train_processed,\n",
        "    validation_data=ds_val_processed,\n",
        "    epochs=20, # Pode ajustar o número de épocas\n",
        "    callbacks=[early_stopping_cnn]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fcdc54a",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Avaliando CNN Mais Profunda para Imagens:\")\n",
        "loss_cnn_deep, accuracy_cnn_deep = model_cnn_deep.evaluate(ds_test_processed)\n",
        "print(f\"Loss no Teste: {loss_cnn_deep:.4f}\")\n",
        "print(f\"Acurácia no Teste: {accuracy_cnn_deep:.4f}\")\n",
        "print(f\"Tempo de treinamento: {time.time() - start_time:.2f} segundos\")\n",
        "print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f79e8a4a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Arquitetura 6: CNN + Camada Recorrente (LSTM) para Texto\n",
        "print(\"--- Treinando CNN + LSTM para Texto ---\")\n",
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e69233a",
      "metadata": {},
      "outputs": [],
      "source": [
        "embedding_dim = 32 # Pode ajustar a dimensão do embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "761932e1",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_cnn_lstm_text = keras.Sequential([\n",
        "    layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    layers.Conv1D(128, 5, activation='relu'),\n",
        "    layers.MaxPooling1D(),\n",
        "    layers.LSTM(64), # Camada LSTM\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid') # Saída binária\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "815e9d79",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_cnn_lstm_text.compile(optimizer='adam',\n",
        "                            loss='binary_crossentropy',\n",
        "                            metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddd74b10",
      "metadata": {},
      "outputs": [],
      "source": [
        "early_stopping_text = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86e4057f",
      "metadata": {},
      "outputs": [],
      "source": [
        "history_cnn_lstm_text = model_cnn_lstm_text.fit(\n",
        "    X_train_text, y_train_text,\n",
        "    epochs=10, # Pode ajustar o número de épocas\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stopping_text]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2533924d",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Avaliando CNN + LSTM para Texto:\")\n",
        "loss_cnn_lstm_text, accuracy_cnn_lstm_text = model_cnn_lstm_text.evaluate(X_test_text, y_test_text)\n",
        "print(f\"Loss no Teste: {loss_cnn_lstm_text:.4f}\")\n",
        "print(f\"Acurácia no Teste: {accuracy_cnn_lstm_text:.4f}\")\n",
        "print(f\"Tempo de treinamento: {time.time() - start_time:.2f} segundos\")\n",
        "print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f71604a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Arquitetura 7: Rede Recorrente (GRU) para Texto\n",
        "print(\"--- Treinando Rede Recorrente (GRU) para Texto ---\")\n",
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c920308b",
      "metadata": {},
      "outputs": [],
      "source": [
        "embedding_dim = 32 # Pode ajustar a dimensão do embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2a0fbdc",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_gru_text = keras.Sequential([\n",
        "    layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    layers.GRU(64), # Camada GRU\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid') # Saída binária\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "082953b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_gru_text.compile(optimizer='adam',\n",
        "                       loss='binary_crossentropy',\n",
        "                       metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9ab9d00",
      "metadata": {},
      "outputs": [],
      "source": [
        "early_stopping_gru = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b80bdd02",
      "metadata": {},
      "outputs": [],
      "source": [
        "history_gru_text = model_gru_text.fit(\n",
        "    X_train_text, y_train_text,\n",
        "    epochs=10, # Pode ajustar o número de épocas\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stopping_gru]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1ef1fe7",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Avaliando Rede Recorrente (GRU) para Texto:\")\n",
        "loss_gru_text, accuracy_gru_text = model_gru_text.evaluate(X_test_text, y_test_text)\n",
        "print(f\"Loss no Teste: {loss_gru_text:.4f}\")\n",
        "print(f\"Acurácia no Teste: {accuracy_gru_text:.4f}\")\n",
        "print(f\"Tempo de treinamento: {time.time() - start_time:.2f} segundos\")\n",
        "print(\"-\" * 40)"
      ]
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}
