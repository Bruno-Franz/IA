{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f279ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Funções de redes neurais reutilizáveis para dados tabulares, texto e imagem.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a104ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a6cffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Tuple, Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c091fb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20637a0f",
   "metadata": {},
   "source": [
    "---------------------- Tabular Data ----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30c9a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar_mlp_sklearn(X_train: np.ndarray, X_test: np.ndarray,\n",
    "                        y_train: Iterable, y_test: Iterable,\n",
    "                        hidden_layer_sizes=(100,), max_iter=300) -> dict:\n",
    "    # treino de MLP usando scikit-learn\n",
    "    \"\"\"Train a scikit-learn MLPClassifier and return metrics.\"\"\"\n",
    "    start = time.time()\n",
    "    clf = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes,\n",
    "                        max_iter=max_iter,\n",
    "                        random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_test)\n",
    "\n",
    "    report = classification_report(y_test, preds, output_dict=True, zero_division=0)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "\n",
    "    return {\n",
    "        \"method\": \"MLPClassifier\",\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"recall\": report[\"weighted avg\"][\"recall\"],\n",
    "        \"f1\": report[\"weighted avg\"][\"f1-score\"],\n",
    "        \"duration\": time.time() - start,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6689077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar_mlp_keras(X_train: np.ndarray, X_test: np.ndarray,\n",
    "                      y_train: Iterable, y_test: Iterable,\n",
    "                      epochs: int = 50) -> dict:\n",
    "    \"\"\"Train a simple Keras MLP for binary classification.\"\"\"\n",
    "    # rede simples em Keras\n",
    "    start = time.time()\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            layers.Dense(128, activation=\"relu\", input_shape=(X_train.shape[1],)),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(64, activation=\"relu\"),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(32, activation=\"relu\"),\n",
    "            layers.Dense(1, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=epochs, validation_split=0.2,\n",
    "              callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                        patience=5,\n",
    "                                                        restore_best_weights=True)],\n",
    "              verbose=0)\n",
    "\n",
    "    loss, _ = model.evaluate(X_test, y_test, verbose=0)\n",
    "    probs = model.predict(X_test, verbose=0).ravel()\n",
    "    preds = (probs > 0.5).astype(int)\n",
    "    report = classification_report(y_test, preds, output_dict=True, zero_division=0)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    return {\n",
    "        \"method\": \"Keras MLP\",\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"recall\": report[\"weighted avg\"][\"recall\"],\n",
    "        \"f1\": report[\"weighted avg\"][\"f1-score\"],\n",
    "        \"loss\": loss,\n",
    "        \"duration\": time.time() - start,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f66149b",
   "metadata": {},
   "source": [
    "---------------------- Image Data ----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a4db04",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = (180, 180)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a053e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preparar_ds_imagem(ds):\n",
    "    # redimensiona e normaliza imagens\n",
    "    def resize_norm(img, label):\n",
    "        img = tf.image.resize(img, IMG_SIZE)\n",
    "        img = img / 255.0\n",
    "        return img, label\n",
    "    return ds.map(resize_norm).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacc17ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar_cnn_simples(ds_train, ds_val, ds_test, num_classes: int,\n",
    "                        epochs: int = 10) -> dict:\n",
    "    \"\"\"Train a small CNN for image classification.\"\"\"\n",
    "    # CNN simples para imagens\n",
    "    start = time.time()\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            layers.Conv2D(32, 3, activation=\"relu\", input_shape=(*IMG_SIZE, 3)),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(64, 3, activation=\"relu\"),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(128, activation=\"relu\"),\n",
    "            layers.Dense(num_classes, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    model.fit(_preparar_ds_imagem(ds_train), validation_data=_preparar_ds_imagem(ds_val),\n",
    "              epochs=epochs, verbose=0)\n",
    "\n",
    "    loss, _ = model.evaluate(_preparar_ds_imagem(ds_test), verbose=0)\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for batch, labels in ds_test:\n",
    "        preds = model.predict(batch, verbose=0)\n",
    "        y_pred.extend(preds.argmax(axis=1))\n",
    "        y_true.extend(labels.numpy())\n",
    "    report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    return {\n",
    "        \"method\": \"Simple CNN\",\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"recall\": report[\"weighted avg\"][\"recall\"],\n",
    "        \"f1\": report[\"weighted avg\"][\"f1-score\"],\n",
    "        \"loss\": loss,\n",
    "        \"duration\": time.time() - start,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5011f1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar_cnn_profundo(ds_train, ds_val, ds_test, num_classes: int,\n",
    "                         epochs: int = 20) -> dict:\n",
    "    \"\"\"Train a deeper CNN with additional layers.\"\"\"\n",
    "    # versão mais profunda da CNN\n",
    "    start = time.time()\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            layers.Conv2D(32, 3, activation=\"relu\", input_shape=(*IMG_SIZE, 3)),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(64, 3, activation=\"relu\"),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(128, 3, activation=\"relu\"),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(256, activation=\"relu\"),\n",
    "            layers.Dropout(0.4),\n",
    "            layers.Dense(num_classes, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    model.fit(\n",
    "        _preparar_ds_imagem(ds_train),\n",
    "        validation_data=_preparar_ds_imagem(ds_val),\n",
    "        epochs=epochs,\n",
    "        callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=5,\n",
    "                                                 restore_best_weights=True)],\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    loss, _ = model.evaluate(_preparar_ds_imagem(ds_test), verbose=0)\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for batch, labels in ds_test:\n",
    "        preds = model.predict(batch, verbose=0)\n",
    "        y_pred.extend(preds.argmax(axis=1))\n",
    "        y_true.extend(labels.numpy())\n",
    "    report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    return {\n",
    "        \"method\": \"Deep CNN\",\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"recall\": report[\"weighted avg\"][\"recall\"],\n",
    "        \"f1\": report[\"weighted avg\"][\"f1-score\"],\n",
    "        \"loss\": loss,\n",
    "        \"duration\": time.time() - start,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bc8fc1",
   "metadata": {},
   "source": [
    "---------------------- Text Data ----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d1cbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar_cnn_texto(train_seq: np.ndarray, test_seq: np.ndarray,\n",
    "                      y_train: Iterable, y_test: Iterable,\n",
    "                      vocab_size: int, embedding_dim: int = 16,\n",
    "                      epochs: int = 10) -> dict:\n",
    "    \"\"\"CNN model for text classification.\"\"\"\n",
    "    # CNN para classificação de texto\n",
    "    start = time.time()\n",
    "    max_length = train_seq.shape[1]\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "            layers.Conv1D(128, 5, activation='relu'),\n",
    "            layers.GlobalMaxPooling1D(),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(1, activation='sigmoid'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_seq, y_train, epochs=epochs, validation_split=0.2, verbose=0)\n",
    "\n",
    "    loss, _ = model.evaluate(test_seq, y_test, verbose=0)\n",
    "    probs = model.predict(test_seq, verbose=0).ravel()\n",
    "    preds = (probs > 0.5).astype(int)\n",
    "    report = classification_report(y_test, preds, output_dict=True, zero_division=0)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    return {\n",
    "        \"method\": \"CNN Text\",\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"recall\": report[\"weighted avg\"][\"recall\"],\n",
    "        \"f1\": report[\"weighted avg\"][\"f1-score\"],\n",
    "        \"loss\": loss,\n",
    "        \"duration\": time.time() - start,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435ca8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar_cnn_lstm_texto(train_seq: np.ndarray, test_seq: np.ndarray,\n",
    "                            y_train: Iterable, y_test: Iterable,\n",
    "                            vocab_size: int, embedding_dim: int = 32,\n",
    "                            epochs: int = 10) -> dict:\n",
    "    \"\"\"CNN + LSTM model for text classification.\"\"\"\n",
    "    # combinação de CNN e LSTM para texto\n",
    "    start = time.time()\n",
    "    max_length = train_seq.shape[1]\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "            layers.Conv1D(128, 5, activation='relu'),\n",
    "            layers.MaxPooling1D(),\n",
    "            layers.LSTM(64),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(1, activation='sigmoid'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_seq, y_train, epochs=epochs, validation_split=0.2,\n",
    "              callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=5,\n",
    "                                                       restore_best_weights=True)],\n",
    "              verbose=0)\n",
    "\n",
    "    loss, _ = model.evaluate(test_seq, y_test, verbose=0)\n",
    "    probs = model.predict(test_seq, verbose=0).ravel()\n",
    "    preds = (probs > 0.5).astype(int)\n",
    "    report = classification_report(y_test, preds, output_dict=True, zero_division=0)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    return {\n",
    "        \"method\": \"CNN+LSTM Text\",\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"recall\": report[\"weighted avg\"][\"recall\"],\n",
    "        \"f1\": report[\"weighted avg\"][\"f1-score\"],\n",
    "        \"loss\": loss,\n",
    "        \"duration\": time.time() - start,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcea31af",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def treinar_gru_texto(train_seq: np.ndarray, test_seq: np.ndarray,\n",
    "                      y_train: Iterable, y_test: Iterable,\n",
    "                      vocab_size: int, embedding_dim: int = 32,\n",
    "                      epochs: int = 10) -> dict:\n",
    "    \"\"\"GRU based model for text classification.\"\"\"\n",
    "    # modelo baseado em GRU\n",
    "    start = time.time()\n",
    "    max_length = train_seq.shape[1]\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "            layers.GRU(64),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(1, activation='sigmoid'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_seq, y_train, epochs=epochs, validation_split=0.2,\n",
    "              callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=5,\n",
    "                                                       restore_best_weights=True)],\n",
    "              verbose=0)\n",
    "\n",
    "    loss, _ = model.evaluate(test_seq, y_test, verbose=0)\n",
    "    probs = model.predict(test_seq, verbose=0).ravel()\n",
    "    preds = (probs > 0.5).astype(int)\n",
    "    report = classification_report(y_test, preds, output_dict=True, zero_division=0)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    return {\n",
    "        \"method\": \"GRU Text\",\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"recall\": report[\"weighted avg\"][\"recall\"],\n",
    "        \"f1\": report[\"weighted avg\"][\"f1-score\"],\n",
    "        \"loss\": loss,\n",
    "        \"duration\": time.time() - start,\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
